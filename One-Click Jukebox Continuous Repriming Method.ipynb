{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mllck/One-Click-Jukebox-Continuous-Repriming-by-Michaels-Lab/blob/main/One-Click%20Jukebox%20Continuous%20Repriming%20Method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAE4EmJ0d9yZ"
      },
      "source": [
        "#(Almost) One-Click Jukebox Continuous Reprime notebook.\n",
        "\n",
        "* Join the Jukebox community at https://discord.gg/aEqXFN9amV\n",
        "\n",
        "* Video guide by Broccaloo for the Jukebox AI : https://vimeo.com/817968335\n",
        "\n",
        "* Explanation video by Michaels Lab about his new notebook: https://youtu.be/BPo5sECkBV4?si=4niezv12iyElPn7J\n",
        "\n",
        "####**How to handle memory problems:** In theory, this notebook is crafted to avoid Out of memory errors, but here's some tricks if you still encounter one:\n",
        "* Restart runtime: At the top of the notebook, click \"Runtime\" and then \"Restart runtime\". Then run everything again. You should do this everytime you start a second run within the same session or after you've interrupted one.\n",
        "* Decrease sample count: Choose a lower number for 'hps.n_samples'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Guide to the below settings:\n",
        "\n",
        "**your_lyrics:** Specify the lyrics Jukebox should attempt to follow. You can paste any lyrics you want in here or leave it blank, which will result in gibberish.\n",
        "\n",
        "**model:**\n",
        "OpenAI has trained a few different models for Jukebox. In this notebook, you can access the 5b_lyrics, 5b and 1b_lyrics models. As you can imagine, the 5b_lyrics model is the superior one, but also requires a stronger GPU to run properly. Which model you should choose depends on the GPU you were assigned, which you can check in the first cell of the notebook. Recommended settings: 5b_lyrics on P100 or T4 GPU, 1b_lyrics on K80 GPU.\n",
        "(5b_lyrics theoretically works on a K80 now, but sampling is going to be super slow.)\n",
        "(5b is like 5b_lyrics, without supporting custom lyrics, so it will generate gibberish vocals)\n",
        "\n",
        "List of the v2 (5b_lyrics & 5b models) & v3 (1b_lyrics model) artist and genre:\n",
        "https://github.com/openai/jukebox/tree/master/jukebox/data/ids\n",
        "\n",
        "**hps.name:** Specifies the name of the folder in Google Drive, where you will find your results in. Make sure to choose a different name for each of your runs, or else the notebook will get confused.\n",
        "\n",
        "**speed_upsampling:** If selected, will upsample much faster, at the cost of the samples sounding slightly \"choppy\".\n",
        "\n",
        "**audio_file:** Specifies which song Jukebox will generate a new audio. Upload the file you want (can be WAV, FLAC, MP3, M4A, OPUS, etc.) to the root directory of your Google Drive and fill in its name above.\n",
        "\n",
        "**sampling_temperature:** Determines the creativity and energy of Jukebox. The higher the temperature, the more chaotic and intense the result will be. You can experiment with this. Recommended to keep between 0.95 and 0.995\n"
      ],
      "metadata": {
        "id": "VoEjmcOifnrN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qEqdj8u0gdN",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0365a8fe-d75f-41b5-ccf0-8787caea7320"
      },
      "source": [
        "#@title ##---Check which GPU you were assigned by running this cell. { vertical-output: true, form-width: \"32%\" }\n",
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-31c84ff0-28c7-8a78-8fa3-59bf3499eee6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "your_lyrics = \"\"\"\"\"\""
      ],
      "metadata": {
        "id": "ovqPkZ6P154X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAdFGF-bqVMY",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f03a2c0c-c1ec-45e0-e0dd-8baae37a8e3f"
      },
      "source": [
        "#@title ##---Main Code { vertical-output: true, form-width: \"50%\" }\n",
        "use_new_jukebox_saveopt = True\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "if use_new_jukebox_saveopt:\n",
        "  !pip install --upgrade git+https://github.com/craftmine1000/jukebox-saveopt.git\n",
        "else:\n",
        "  !pip install --upgrade git+https://github.com/craftmine1000/jukebox-saveopt.git\n",
        "\n",
        "import jukebox\n",
        "import torch as t\n",
        "import torch.nn.functional as F\n",
        "import librosa\n",
        "import os\n",
        "import numpy as np #Import numpy\n",
        "from IPython.display import Audio\n",
        "from jukebox.make_models import make_vqvae, make_prior, MODELS, make_model\n",
        "from jukebox.hparams import Hyperparams, setup_hparams\n",
        "from jukebox.sample import sample_single_window, _sample, \\\n",
        "                           sample_partial_window, upsample, \\\n",
        "                           load_prompts\n",
        "from jukebox.utils.dist_utils import setup_dist_from_mpi\n",
        "from jukebox.utils.torch_utils import empty_cache\n",
        "rank, local_rank, device = setup_dist_from_mpi()\n",
        "\n",
        "model = \"5b_lyrics\" #@param ['5b_lyrics', '5b', '1b_lyrics']\n",
        "hps = Hyperparams()\n",
        "hps.sr = 44100\n",
        "hps.n_samples = 1\n",
        "hps.name = '/content/gdrive/My Drive/' #@param {type: \"string\"}\n",
        "chunk_size = 128 if model==\"5b_lyrics\" else 128\n",
        "hps.hop_fraction = [1, 4, .125]\n",
        "batch_sizes = [4, 6, 2] if model==\"5b_lyrics\" else [2, 4, 2]\n",
        "hps.levels = 3\n",
        "\n",
        "# Define max_batch_size here\n",
        "max_batch_size = 8  # You might need to adjust this value based on your GPU memory\n",
        "\n",
        "if not use_new_jukebox_saveopt:\n",
        "  for i in range(2):\n",
        "    if hps.hop_fraction[i] > 1:\n",
        "      hps.hop_fraction[i] = 1\n",
        "\n",
        "primer_length_in_seconds = librosa.get_duration(filename=hps.name + 'primer.wav')\n",
        "duration = (int(primer_length_in_seconds * hps.sr) // 128) * 128\n",
        "hps.sample_length = duration\n",
        "\n",
        "raw_audio = load_prompts([hps.name + 'primer.wav'], duration, hps)\n",
        "\n",
        "#print(raw_audio)\n",
        "#print(raw_audio.shape)\n",
        "#print(t.max(t.abs(raw_audio)))\n",
        "# Inside the vqvae.decode function in jukebox/vqvae/vqvae.py\n",
        "def decode(self, zs, start_level=0, end_level=None, bs_chunks=1, length_chunks=1): #Set a default value for length_chunks\n",
        "# Modified logic to prevent length_chunks from being 0\n",
        "    # Check if the input tensor is empty along dim=1\n",
        "    if zs[-1].shape[1] == 0:  # If the last level's tensor has 0 length, return zeros\n",
        "        return t.zeros(zs[0].shape[0], 0, device=zs[0].device, dtype=zs[0].dtype)\n",
        "\n",
        "    length = zs[-1].shape[1]\n",
        "    length_chunks = max(1, int(np.ceil(length / self.hps.sample_length)))\n",
        "\n",
        "try:\n",
        "  try:\n",
        "    zs = t.load(f'{hps.name}level_1/data.pth.tar')['zs']\n",
        "  except:\n",
        "    zs = t.load(f'{hps.name}tokens.t')\n",
        "except:\n",
        "  zs = [t.zeros(hps.n_samples,0,dtype=t.long, device='cpu') for _ in range(hps.levels)]\n",
        "\n",
        "vqvae, *priors = MODELS[model]\n",
        "vqvae = make_vqvae(setup_hparams(vqvae, dict(sample_length = 1048576)), device)\n",
        "#vqvae.c_to(device)\n",
        "if zs[-1].shape[1] < duration // 128:\n",
        "  top_prior = make_prior(setup_hparams(priors[-1], dict()), vqvae, device)\n",
        "  if use_new_jukebox_saveopt:\n",
        "    top_prior.c_to(device)\n",
        "\n",
        "\n",
        "speed_upsampling = True  #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "# Assuming select_artist and select_genre are defined somewhere before this point\n",
        "select_artist = \"unknown\"  # You need to define these variables or get them from user input\n",
        "select_genre = \"unknown\"    # You need to define these variables or get them from user input\n",
        "#zs=[t.zeros(hps.n_samples,0,dtype=t.long, device='cpu') for _ in range(hps.levels)]\n",
        "\n",
        "sampling_temperature = 0.97#@param {type: \"number\"}\n",
        "artist_condition = ''#@param {type: \"string\"}\n",
        "genre_condition = ''#@param {type: \"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "timing_mode = 'tokens'#@param ['tokens', 'bpm']\n",
        "\n",
        "#@markdown ####Tokens/Seconds Mode\n",
        "\n",
        "amount = 0#@param {type: \"integer\"}\n",
        "\n",
        "#@markdown ####BPM Mode\n",
        "\n",
        "bpm = 0#@param {type: \"number\"}\n",
        "bars = 0#@param {type: \"integer\"}\n",
        "beats = 0#@param {type: \"integer\"}\n",
        "\n",
        "beats += bars * 4\n",
        "\n",
        "if True:\n",
        "  #zs = [t.zeros(hps.n_samples,0,dtype=t.long, device='cpu') for _ in range(hps.levels)]\n",
        "  try:\n",
        "    top_prior\n",
        "  except:\n",
        "    top_prior = None\n",
        "\n",
        "  if top_prior:\n",
        "    top_prior.prior.transformer.del_cache()\n",
        "    first = True\n",
        "    while zs[2].shape[1] < duration // top_prior.raw_to_tokens:\n",
        "      left_to_sample = duration // top_prior.raw_to_tokens - zs[2].shape[1]\n",
        "\n",
        "      amnt_to_sample = []\n",
        "      zs_size_projected = zs[2].shape[1]\n",
        "      for i in range(batch_sizes[2] // hps.n_samples):\n",
        "\n",
        "        if timing_mode == 'tokens':\n",
        "          new_tokens = amount\n",
        "        elif timing_mode == 'seconds':\n",
        "          seconds_done = round(zs_size_projected / (hps.sr / top_prior.raw_to_tokens))\n",
        "          seconds_done += amount\n",
        "          new_tokens = round(seconds_done * (hps.sr / top_prior.raw_to_tokens)) - zs_size_projected\n",
        "        elif timing_mode == 'bpm':\n",
        "          beats_done = round((zs_size_projected / (hps.sr / top_prior.raw_to_tokens)) / (60 / bpm))\n",
        "          beats_done += beats\n",
        "          new_tokens = round(beats_done * (60 / bpm) * (hps.sr / top_prior.raw_to_tokens)) - zs_size_projected\n",
        "\n",
        "        assert new_tokens < top_prior.n_ctx, 'too long sections m8'\n",
        "\n",
        "        amnt_to_sample.append(min(new_tokens, left_to_sample))\n",
        "        left_to_sample -= new_tokens\n",
        "        zs_size_projected += new_tokens\n",
        "        if left_to_sample <= 0:\n",
        "          break\n",
        "\n",
        "      print('amnt_to_sample:', amnt_to_sample)\n",
        "      max_to_sample = max(amnt_to_sample)\n",
        "      #print('max_to_sample:', max_to_sample)\n",
        "      print(zs[2].shape[1], '/', duration // top_prior.raw_to_tokens, '| aprox windows left:', round((duration // top_prior.raw_to_tokens - zs[2].shape[1]) / max_to_sample, 1))\n",
        "      metas = []\n",
        "      xs_pre_cat = []\n",
        "\n",
        "      zs_size_projected = zs[2].shape[1]\n",
        "      for i in range(len(amnt_to_sample)):\n",
        "        amnt_to_encode = top_prior.n_ctx - max_to_sample\n",
        "        start = zs_size_projected - amnt_to_encode\n",
        "        metas.extend([dict(\n",
        "            artist = artist_condition,\n",
        "            genre = genre_condition,\n",
        "            total_length = duration,\n",
        "            offset = max(0, start) * top_prior.raw_to_tokens,\n",
        "            lyrics = your_lyrics\n",
        "            )] * hps.n_samples\n",
        "        )\n",
        "\n",
        "        if zs_size_projected > 0:\n",
        "          enc = raw_audio[:, max(0, start * top_prior.raw_to_tokens) : (start + top_prior.n_ctx) * top_prior.raw_to_tokens]\n",
        "          xs = vqvae.encode(enc, bs_chunks=raw_audio.shape[0])\n",
        "          #x = vqvae.decode(xs[2:], start_level=2).cpu().numpy()\n",
        "          #for i in range(hps.n_samples):\n",
        "          #  librosa.output.write_wav(f'{hps.name}top_level_encdec_{i}.wav', x[i][:], sr=hps.sr)\n",
        "\n",
        "          #print('xs:', xs[2].shape)\n",
        "          xss = xs[-1][:,:-max_to_sample]\n",
        "          #print('xss:', xss.shape)\n",
        "          #xss = xss[:, max(0,top_prior.n_ctx - (xss.shape[1] + max_to_sample)):]\n",
        "          #print('xss:', xss.shape)\n",
        "        else:\n",
        "          xss = t.zeros(hps.n_samples,0,dtype=t.long, device='cpu')\n",
        "\n",
        "        xs_pre_cat.append(xss)\n",
        "        zs_size_projected += amnt_to_sample[i]\n",
        "\n",
        "      labels = top_prior.labeller.get_batch_labels(metas, 'cuda')\n",
        "\n",
        "      #print('metas:', metas)\n",
        "      #print('labels:', labels)\n",
        "\n",
        "      mx = max(map(lambda x: x.shape[1], xs_pre_cat))\n",
        "      #print('mx:', mx)\n",
        "      xs_pre_cat = list(map(lambda x: F.pad(x, (mx - x.shape[1], 0), mode='constant', value=0), xs_pre_cat))\n",
        "\n",
        "      #print('xs_pre_cat:', list(map(lambda x: x.shape, xs_pre_cat)))\n",
        "\n",
        "      xs = [\n",
        "        t.zeros(hps.n_samples,0,dtype=t.long, device='cpu'),\n",
        "        t.zeros(hps.n_samples,0,dtype=t.long, device='cpu'),\n",
        "        t.cat(xs_pre_cat, dim=0)\n",
        "      ]\n",
        "\n",
        "      #print(xs[2].shape)\n",
        "      #print(max_to_sample)\n",
        "      sampling_kwargs = dict(temp=sampling_temperature, fp16=True, max_batch_size=batch_sizes[2], chunk_size=chunk_size)\n",
        "\n",
        "      if use_new_jukebox_saveopt:\n",
        "        xs=sample_partial_window(xs, labels, sampling_kwargs, 2, top_prior, max_to_sample, hps, autosave=False)\n",
        "      else:\n",
        "        xs=sample_partial_window(xs, labels, sampling_kwargs, 2, top_prior, max_to_sample, hps)\n",
        "\n",
        "      foobar = []\n",
        "      for i in range(len(amnt_to_sample)):\n",
        "        foobar.append(xs[2][i*hps.n_samples:(i+1)*hps.n_samples,-max_to_sample:][:,:amnt_to_sample[i]])\n",
        "      #print('foobar:', foobar)\n",
        "      zs[2] = t.cat((zs[2], t.cat(foobar, dim=1)), dim=1)\n",
        "      t.save(zs, f'{hps.name}tokens.t')\n",
        "      first = False\n",
        "\n",
        "  metas = [dict(artist = artist_condition,\n",
        "                genre = genre_condition,\n",
        "                total_length = duration,\n",
        "                offset = 0,\n",
        "                lyrics = your_lyrics,\n",
        "                ), ] * hps.n_samples\n",
        "\n",
        "  if False: zs = t.load(f'{hps.name}tokens.t')\n",
        "\n",
        "assert zs[2].shape[1]>=2048, f'Please first generate at least 2048 tokens at the top level, currently you have {zs[2].shape[1]}'\n",
        "hps.sample_length = zs[2].shape[1]*128\n",
        "\n",
        "# Set this False if you are on a local machine that has enough memory (this allows you to do the\n",
        "# lyrics alignment visualization). For a hosted runtime, we'll need to go ahead and delete the top_prior\n",
        "# if you are using the 5b_lyrics model.\n",
        "if False:\n",
        "  del top_prior\n",
        "  empty_cache()\n",
        "  top_prior=None\n",
        "\n",
        "upsamplers = [make_prior(setup_hparams(prior, dict()), vqvae, 'cpu') for prior in priors[:-1]]\n",
        "empty_cache()\n",
        "\n",
        "sampling_kwargs = [dict(temp=0.975, fp16=True, max_batch_size=batch_sizes[0], chunk_size=128),\n",
        "                    dict(temp=0.975, fp16=True, max_batch_size=batch_sizes[1], chunk_size=128),\n",
        "                    None]\n",
        "\n",
        "labels = [prior.labeller.get_batch_labels(metas, 'cuda') for prior in upsamplers] + [upsamplers[0].labeller.get_batch_labels(metas, 'cuda')]\n",
        "empty_cache()\n",
        "\n",
        "empty_cache()\n",
        "for prior in upsamplers:\n",
        "  prior.prior.transformer.del_cache()\n",
        "empty_cache()\n",
        "zs = upsample(zs, labels, sampling_kwargs, [*upsamplers, top_prior], hps)\n",
        "disconnect_runtime_after_finish = True #@param {type: \"boolean\"}\n",
        "if disconnect_runtime_after_finish == True:\n",
        "  from google.colab import runtime\n",
        "  runtime.unassign()\n",
        "#@markdown ---\n",
        "#@markdown ####This cell will work for about 3-5 hours.\n",
        "\n",
        "#@markdown ####It's not recommended if you put it in 5b_lyrics model with a T4 GPU, because it will take a long couple of hours and will be use a lot of your GPU's RAM. If not, you have to opt for using 1b_lyrics."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Collecting git+https://github.com/craftmine1000/jukebox-saveopt.git\n",
            "  Cloning https://github.com/craftmine1000/jukebox-saveopt.git to /tmp/pip-req-build-e0h0fn14\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/craftmine1000/jukebox-saveopt.git /tmp/pip-req-build-e0h0fn14\n",
            "  Resolved https://github.com/craftmine1000/jukebox-saveopt.git to commit 5b76e9e07eb15dba6fd79da99d76d1ecb32a7ea5\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: fire>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from jukebox==1.0) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.45.0 in /usr/local/lib/python3.11/dist-packages (from jukebox==1.0) (4.67.1)\n",
            "Requirement already satisfied: soundfile>=0.10.3.post1 in /usr/local/lib/python3.11/dist-packages (from jukebox==1.0) (0.13.0)\n",
            "Requirement already satisfied: unidecode>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from jukebox==1.0) (1.3.8)\n",
            "Requirement already satisfied: numba>=0.48.0 in /usr/local/lib/python3.11/dist-packages (from jukebox==1.0) (0.60.0)\n",
            "Requirement already satisfied: librosa>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from jukebox==1.0) (0.10.2.post1)\n",
            "Requirement already satisfied: mpi4py>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from jukebox==1.0) (4.0.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire>=0.1.3->jukebox==1.0) (2.5.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.7.2->jukebox==1.0) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.7.2->jukebox==1.0) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.7.2->jukebox==1.0) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.7.2->jukebox==1.0) (1.6.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.7.2->jukebox==1.0) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.7.2->jukebox==1.0) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.7.2->jukebox==1.0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.7.2->jukebox==1.0) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.7.2->jukebox==1.0) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.7.2->jukebox==1.0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.7.2->jukebox==1.0) (1.1.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.48.0->jukebox==1.0) (0.43.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.10.3.post1->jukebox==1.0) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.10.3.post1->jukebox==1.0) (2.22)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa>=0.7.2->jukebox==1.0) (24.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.7.2->jukebox==1.0) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.7.2->jukebox==1.0) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa>=0.7.2->jukebox==1.0) (3.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.7.2->jukebox==1.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.7.2->jukebox==1.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.7.2->jukebox==1.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.7.2->jukebox==1.0) (2024.12.14)\n",
            "Using cuda True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-3432636aee67>:44: FutureWarning: get_duration() keyword argument 'filename' has been renamed to 'path' in version 0.10.0.\n",
            "\tThis alias will be removed in version 1.0.\n",
            "  primer_length_in_seconds = librosa.get_duration(filename=hps.name + 'primer.wav')\n",
            "<ipython-input-3-3432636aee67>:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  zs = t.load(f'{hps.name}level_1/data.pth.tar')['zs']\n",
            "<ipython-input-3-3432636aee67>:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  zs = t.load(f'{hps.name}tokens.t')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from azure\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/jukebox/make_models.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = t.load(restore, map_location=memory_map)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restored from /root/.cache/jukebox/models/5b/vqvae.pth.tar\n",
            "0: Loading vqvae in eval mode\n",
            "Loading artist IDs from /usr/local/lib/python3.11/dist-packages/jukebox/data/ids/v2_artist_ids.txt\n",
            "Loading artist IDs from /usr/local/lib/python3.11/dist-packages/jukebox/data/ids/v2_genre_ids.txt\n",
            "Level:2, Cond downsample:None, Raw to tokens:128, Sample length:1048576\n",
            "Downloading from azure\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Important links:\n",
        "\n",
        "* Official blog: https://openai.com/blog/jukebox/\n",
        "* Original repo: https://github.com/openai/jukebox/\n",
        "\n",
        "* License: Non-commercial, for details see: https://github.com/openai/jukebox/blob/master/LICENSE\n",
        "\n",
        "* The original notebook was created by: Jaime v2.0 - Since 2018. (https://www.youtube.com/channel/UCWbk5lrnDGB6SnhnIwcDZ4w)"
      ],
      "metadata": {
        "id": "Lu12YwYVDbJ3"
      }
    }
  ]
}